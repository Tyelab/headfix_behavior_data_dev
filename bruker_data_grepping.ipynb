{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13e79f5a-afdd-4b77-a0cc-e9a072fb697f",
   "metadata": {},
   "source": [
    "# Bruker Data Grepping and Alignment Notebook\n",
    "### Jeremy Delahanty June 2021\n",
    "\n",
    "Intended to grep different files/projects/datasets from user input and retain them for use in analysis/display later. The lack of unified filenaming structures between projects will break the code... A convetion of XXX### for animal names has been established for Austin's projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "236756af-545f-4c82-bfc7-7f22a45d8a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pynwb import NWBFile, TimeSeries, NWBHDF5IO\n",
    "from typing import Tuple\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def109c7-4a96-41a8-b0c5-a66ab01b0f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_basepath = \"Y:/\"\n",
    "# project_dict = {\"specialk\": [\"learned_helplessness\", \"chronic_mild_stress\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62578e70-c52a-4a7e-9d62-b7c5d0b02268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found All Selected Teams\n",
      "Teams Returned:\n",
      "specialk \n"
     ]
    }
   ],
   "source": [
    "def grep_teams(team_selection: list = None, lab_basepath: Path = Path(\"Y:/\")) -> Tuple[list, list]:\n",
    "    \"\"\"\n",
    "    Grabs team list from server based on user's input.\n",
    "    \n",
    "    User can define which teams they want to use for their analyses and\n",
    "    the function will glob the paths for their selection.\n",
    "    \n",
    "    Args:\n",
    "        team_selection:\n",
    "            List of strings for teams of interest\n",
    "            Default is empty list\n",
    "        lab_basepath:\n",
    "            Basepath for server location on machine\n",
    "            Default is Y:/ for mapped Windows drive\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "        team_list:\n",
    "            List of team path grabbed from server successfully\n",
    "        missing_teams:\n",
    "            List of selected teams that were not found\n",
    "    \"\"\"\n",
    "\n",
    "    # Take basepath and glob all available files and directories\n",
    "    team_glob = Path(lab_basepath).glob(\"*\")\n",
    "    \n",
    "    # Check if no team was specifically asked for, tell user we're gathering all teams\n",
    "    if team_selection == []:\n",
    "\n",
    "        print(\"Gathering all teams...\")\n",
    "\n",
    "        # List comprehension for returning all directories in Tye Lab server\n",
    "        team_list = [team for team in team_glob if team.is_dir()]\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # List comprehension for returning only directories user wants in the Tye Lab server \n",
    "        team_list = [team for team in team_glob if team.name in team_selection and team.is_dir()]\n",
    "    \n",
    "    # Create temporary list for checking if selected teams exist\n",
    "    tmp = []\n",
    "\n",
    "    # For the teams that were globbed successfully, append the team to the temp list\n",
    "    for globbed_team in team_list:\n",
    "        tmp.append(globbed_team.name)\n",
    "    \n",
    "    # Compare team selection with returned teams using sets, convert to list\n",
    "    missing_teams = list(set(team_selection) - set(tmp))\n",
    "    \n",
    "    # If the missing_teams list is empty, the program found all requested teams\n",
    "    if missing_teams == []:\n",
    "        print(\"Found All Selected Teams\")\n",
    "    \n",
    "    # Else, some teams weren't found. Tell the user which teams weren't found.\n",
    "    else:\n",
    "        print(\"Failed to find team(s):\", missing_teams)\n",
    "   \n",
    "    # Show user which teams were returned\n",
    "    print(\"Teams Returned:\")\n",
    "    for team in team_list:\n",
    "        print(\"{} \".format(team.name))\n",
    "    \n",
    "    # Return the list of projects gathered\n",
    "    return team_list, missing_teams\n",
    "\n",
    "team_list, missing_teams = grep_teams([\"specialk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47d606e-6e66-4ffb-a644-1af2834b8e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned Directories: \n",
      "Y:\\specialk\\learned_helplessness\n"
     ]
    }
   ],
   "source": [
    "def choose_projects(team_list, project_selection={}):\n",
    "    \"\"\"\n",
    "    Generates project paths list based on user's selection.\n",
    "    \n",
    "    User can define which project they want to use for their analyses and\n",
    "    this function generates the paths for their selection.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1: list\n",
    "        List of strings for teams of interest from grep_teams()\n",
    "    arg2: dict\n",
    "        Dictionary of values that will be used to create specific\n",
    "        paths for selected teams and their projects\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    1. list\n",
    "        List of team/project Paths to grep in next steps\n",
    "    \"\"\"\n",
    "\n",
    "    # Make dictionary using the teams in team_list as keys\n",
    "    project_dict = {team: [] for team in team_list}\n",
    "\n",
    "    # For each time in the team_list, append the Path name's project's values\n",
    "    for team in team_list:\n",
    "        project_dict[team].append(project_selection[team.name])\n",
    "    \n",
    "    # Make empty project list\n",
    "    project_dir_list = []\n",
    "\n",
    "    for team in project_dict.keys():\n",
    "        for project in range(len(project_dict[team][0])):\n",
    "            project_dir_list.append(team / project_dict[team][0][project])\n",
    "    \n",
    "    print(\"Returned Directories: \")\n",
    "\n",
    "    for directory in project_dir_list:\n",
    "        print(directory)\n",
    "    \n",
    "    return project_dir_list\n",
    "    \n",
    "project_list = choose_projects(team_list, project_selection={\"specialk\": [\"learned_helplessness\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c423b7-92e8-45ba-9af8-4103534166d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing only E animals...\n",
      "learned_helplessness LHE011\n",
      "learned_helplessness LHE012\n",
      "learned_helplessness LHE013\n",
      "learned_helplessness LHE014\n",
      "learned_helplessness LHE015\n",
      "learned_helplessness LHE016\n"
     ]
    }
   ],
   "source": [
    "def choose_animals(project_list, animal_group=\"all\"):\n",
    "    \"\"\"\n",
    "    Generates animal paths list based on user's selection.\n",
    "    \n",
    "    User can define which cohort of animals they want to use \n",
    "    for their analyses. This function generates the paths for \n",
    "    their selection that meet specified conditions.\n",
    "    \n",
    "    Args:\n",
    "\n",
    "        project_list:\n",
    "            List of strings for projects of interest from choose_projects()\n",
    "        animal_group:\n",
    "            String of value for which animal paths to gather.\n",
    "            Default value is all.\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "        list: List of team/project/animal Paths to grep in next steps\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create empty animal list for path generation\n",
    "    animal_list = []\n",
    "    \n",
    "    # If the animal group is left as default/specified as all, grab all animals\n",
    "    if animal_group == \"all\":\n",
    "        print(\"Grabbing all animals...\")\n",
    "        \n",
    "        # For each project directory in the project list\n",
    "        for project_dir in project_list:\n",
    "            \n",
    "            # For each animal globbed in the project directory\n",
    "            for animal in project_dir.glob(\"*\"):\n",
    "                \n",
    "                # Append the animal's path to the animal_list\n",
    "                print(project_dir.name, animal.name)\n",
    "                animal_list.append(animal)\n",
    "    \n",
    "    # Else, only select animals from the specified group\n",
    "    else:\n",
    "        print(\"Grabbing only {} animals...\".format(animal_group))\n",
    "\n",
    "        # Format the animal group with the user's input\n",
    "        animal_group = \"[A-Z]{2}\" + animal_group + \"\\d{3}\"\n",
    "        \n",
    "        # For each project_directory in project_list\n",
    "        for project_dir in project_list:\n",
    "\n",
    "            # For each animal globbed in project directory\n",
    "            for animal in project_dir.glob(\"*\"):\n",
    "                \n",
    "                # Use regex to grab only the requested animal\n",
    "                r = re.search(animal_group, string=animal.name)\n",
    "                \n",
    "                # If the search returns None, the animal didn't match the request\n",
    "                # Skip over it with pass.\n",
    "                if r is None:\n",
    "                    pass\n",
    "                \n",
    "                # If something is returned, take the match object's value and append\n",
    "                # the animal to the project directory.\n",
    "                else:\n",
    "                    print(project_dir.name, r.group(0))\n",
    "                    animal_list.append(project_dir / r.group(0))\n",
    "    \n",
    "    # Finally, return the list of animals\n",
    "    return animal_list\n",
    "\n",
    "animal_list = choose_animals(project_list, animal_group=\"E\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7f50cbd-7489-476a-bc55-90794f3092d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing specified directories... \n",
      " ['twop']\n",
      "\n",
      "Returning Directories:\n",
      "Y:\\specialk\\learned_helplessness\\LHE011\\twop\n",
      "Y:\\specialk\\learned_helplessness\\LHE012\\twop\n",
      "Y:\\specialk\\learned_helplessness\\LHE013\\twop\n",
      "Y:\\specialk\\learned_helplessness\\LHE014\\twop\n",
      "Y:\\specialk\\learned_helplessness\\LHE015\\twop\n",
      "Y:\\specialk\\learned_helplessness\\LHE016\\twop\n"
     ]
    }
   ],
   "source": [
    "def choose_data(animal_list, data_group=[], verbose=True):\n",
    "    \"\"\"\n",
    "    Generates animal's data paths list based on user's selection.\n",
    "    \n",
    "    User can define which dataset to use for the animals they \n",
    "    want to use for their analyses. This function generates the\n",
    "    paths for their selection that meet specified conditions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1: list\n",
    "        List of paths for animals of interest from choose_animals()\n",
    "    arg2: list\n",
    "        List of strings for which datasets to gather.\n",
    "        Default value is all.\n",
    "    arg3: bool\n",
    "        Boolean argument for verbose output of paths found or\n",
    "        not found by the function. Default is True.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    1. list\n",
    "        List of team/project/animal/dataset Paths to grep in\n",
    "        next steps\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create empty data list for path generation\n",
    "    data_dir_list = []\n",
    "    \n",
    "    # If data_group is left as default or specified as empty,\n",
    "    # grab all folders\n",
    "    if data_group == []:\n",
    "        print(\"Grabbing all data folders...\")\n",
    "        \n",
    "        # For each animal in the animal list\n",
    "        for animal in animal_list:\n",
    "            \n",
    "            # For the data_dir in the globbed animal_path\n",
    "            for data_dir in animal.glob(\"*\"):\n",
    "                \n",
    "                # Append the data_dir to the data_list\n",
    "                print(\"Grabbing\", animal.name, data_dir.name)\n",
    "                data_list.append(data)\n",
    "    \n",
    "    #TODO: Make verbose into its own function\n",
    "    elif len(data_group) > 0 and verbose is True:\n",
    "        print(\"Grabbing...\")\n",
    "        for data_type in data_group:\n",
    "            print(data_type, \"data\")\n",
    "\n",
    "        print(\"\\nFrom Projects(s)...\")\n",
    "        project_list = list(set([project.parent.name for project in animal_list]))\n",
    "        for project in project_list:\n",
    "            print(project)\n",
    "            \n",
    "        print(\"\\nIn Team(s)...\")\n",
    "        team_list = list(set([team.parent.parent.name for team in animal_list]))\n",
    "        for team in team_list:\n",
    "            print(team)\n",
    "        print(\"\\nFor Animals...\")\n",
    "        for animal in animal_list:\n",
    "            print(animal.name)\n",
    "        \n",
    "        print(\"\\nChecking for directories...\")\n",
    "        for animal in animal_list:\n",
    "            for data_type in data_group:\n",
    "                if (animal / data_type).is_dir():\n",
    "                    print(\"Found\", animal.name, data_type)\n",
    "                    data_dir_list.append(animal / data_type)\n",
    "                else:\n",
    "                    print(\"Not Found!\", animal.name, data_type)\n",
    "    else:\n",
    "       \n",
    "        #TODO: Write a function for checking\n",
    "        print(\"Grabbing specified directories...\", \"\\n\", data_group)\n",
    "        \n",
    "        for animal in animal_list:\n",
    "            for data_type in data_group:\n",
    "                if (animal / data_type).is_dir():\n",
    "                    data_dir_list.append(animal / data_type)\n",
    "                else:\n",
    "                    print(animal.name, data_type, \"Not Found!\")\n",
    "    \n",
    "    # Tell user which directories were returned\n",
    "    print(\"\\nReturning Directories:\")\n",
    "    for data_dir in data_dir_list:\n",
    "        print(data_dir)\n",
    "\n",
    "    return data_dir_list\n",
    "                \n",
    "\n",
    "data_dir_list = choose_data(animal_list, data_group=[\"twop\"], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac8d9c09-abd4-4bd3-ab54-11c010d7ce30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING!!! LHE011 twop 20210602 raw data not converted!\n"
     ]
    }
   ],
   "source": [
    "def grep_twop_raw_behavior_data(data_directory, convert_missing_data=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Checks whether raw 2P behavior data has been converted to .csv for all available days.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1: Path\n",
    "        Parent directory of raw behavior data file\n",
    "        \n",
    "    arg2: bool\n",
    "        Whether to invoke raw data file conversion through Bruker's raw converter\n",
    "        Default False; no containerized ripper is in place (7/29/21)...\n",
    "        \n",
    "    arg3: bool\n",
    "        Whether to print checking process for the user.\n",
    "        Default True\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    1. list\n",
    "        Existing raw behavior data file paths \n",
    "    \"\"\"\n",
    "    \n",
    "    checked_behavior_file_list = []\n",
    "    \n",
    "    missing_behavior_dir_list = []\n",
    "    \n",
    "    raw_behavior_dir_search = data_directory.glob(\"*/*\")\n",
    "    \n",
    "    raw_behavior_dir_dict = {result.parent : [file for file in result.glob(\"*.csv\")] for result in raw_behavior_dir_search if result.is_dir()}\n",
    "    \n",
    "    if verbose is True:\n",
    "        for key in raw_behavior_dir_dict:\n",
    "            print(\"\\nChecking if\", key.parents[1].name, key.parents[0].name, key.name, \"raw behavior is converted...\")\n",
    "            if len(raw_behavior_dir_dict[key]) == 0:\n",
    "                print(\"\\nWARNING!!!\", key.parents[1].name, key.parents[0].name, key.name, \"raw behavior not converted!\")\n",
    "                missing_behavior_dir_list.append(raw_behavior_dir_dict[key])\n",
    "            else:\n",
    "                print(key.parents[1].name, key.parents[0].name, key.name,  \"raw behavior converted!\")\n",
    "                checked_behavior_file_list.append(raw_behavior_dir_dict[key][0])\n",
    "                \n",
    "        print(\"\\nReturning checked files:\")\n",
    "        for file in checked_behavior_file_list:\n",
    "            print(file)\n",
    "            \n",
    "        \n",
    "    else:\n",
    "        # TODO: This should be a warning/exception that is logged and/or saved somewhere maybe...\n",
    "        for key in raw_behavior_dir_dict:\n",
    "            if len(raw_behavior_dir_dict[key]) == 0:\n",
    "                print(\"WARNING!!!\", key.parents[1].name, key.parents[0].name, key.name, \"raw data not converted!\")\n",
    "            else:\n",
    "                checked_behavior_file_list.append(raw_behavior_dir_dict[key][0])\n",
    "\n",
    "    return checked_behavior_file_list\n",
    "\n",
    "checked_behavior_file_list = grep_twop_raw_behavior_data(data_dir_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfc20455-f1b0-4bcf-a4da-e01cbb3bc054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grep_twop_behavior_config(checked_behavior_file_list):\n",
    "    \"\"\"\n",
    "    Generates animal's configuration paths list based on user's selection\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1: list\n",
    "        List of paths for animals of interest from choose_data()\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    1. list\n",
    "        List of 2P behavior configuration Paths\n",
    "    \"\"\"\n",
    "    \n",
    "    twop_config_list = []\n",
    "    \n",
    "    for directory in checked_behavior_file_list:\n",
    "        parent_dir = directory.parents[1]\n",
    "        search = parent_dir.glob(\"*config.json\")\n",
    "        for result in search:\n",
    "            twop_config_list.append(result)\n",
    "            \n",
    "    return twop_config_list\n",
    "            \n",
    "twop_config_list = grep_twop_behavior_config(checked_behavior_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0c8ee8d-0fa3-4179-9edd-94401e503196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210611_LHE011_plane0-081_Cycle00001_VoltageRecording_001.csv\n",
      "Wall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def clean_2p_behavior(twop_raw_behavior_file, raw_keys=[\"Lick\", \"Airpuff\", \"Liquid\", \"Speaker\"], df_keys=[\"on\", \"off\"]):\n",
    "    \"\"\"\n",
    "    Takes in raw 2P behavior file produced by Bruker and generates timestamps for all events.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1: Path\n",
    "        Path to raw behavior data\n",
    "    arg2: list\n",
    "        List of raw data keys to clean\n",
    "        Default is Lick, Airpuff, Liquid, and Speaker data\n",
    "    arg3: list\n",
    "        List of keys to create for dataframe\n",
    "        Default is onset AND offset of each event\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    1. dict\n",
    "        Dictionary containing timestamps for stimuli\n",
    "    2. dict\n",
    "        Dictionary containing timestamps for behavior\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Create list of requested keys by concatenating each value in the raw and df keys arguments\n",
    "    requested_keys = []\n",
    "    \n",
    "    for raw_key in raw_keys:\n",
    "        for df_key in df_keys:\n",
    "            requested_keys.append(raw_key + \"_\" + df_key)\n",
    "    \n",
    "    \n",
    "    # Do the cleaning for the supplied raw data file\n",
    "    # Tell the user which file is being processed\n",
    "    print(\"Cleaning:\", twop_raw_behavior_file.name)\n",
    "\n",
    "    # Adapting code by Kyle Fischer, June 2021 thru line 44\n",
    "    # Read the raw .csv from Bruker's Voltage Recording\n",
    "    raw_behavior_df = pd.read_csv(twop_raw_behavior_file, index_col=\"Time(ms)\").rename(columns=lambda col:col.strip())\n",
    "\n",
    "    # Any value below 3V is certainly noise.  Set them to zero by filtering the raw dataframe\n",
    "    raw_behavior_df = raw_behavior_df > 3\n",
    "\n",
    "    # Convert all values to int for pandas.DataFrame.diff() to yield negative values for stop times\n",
    "    # and then perform the .diff() function and finally use .fillna() to eliminate NaN values\n",
    "    raw_behavior_df = raw_behavior_df.astype(int).diff().fillna(0)\n",
    "\n",
    "    # Create empty dictionary for cleaned timestamps\n",
    "    clean_stimuli_dict = {}\n",
    "    clean_behavior_dict = {}\n",
    "    \n",
    "    stimuli_keys = [key for key in requested_keys if \"Lick\" not in key]\n",
    "    behavior_keys = [key for key in requested_keys if \"Lick\" in key]\n",
    "\n",
    "    # Query the raw datafile for each condition.  1 represents \"On\" signal while -1 represents \"Off\"\n",
    "    for key in stimuli_keys:\n",
    "        if \"on\" in key:\n",
    "            clean_stimuli_dict[key] = raw_behavior_df.query(key.split(\"_\")[0] + \" == 1\").index.tolist()\n",
    "        else:\n",
    "            clean_stimuli_dict[key] = raw_behavior_df.query(key.split(\"_\")[0] + \" == -1\").index.tolist()\n",
    "    \n",
    "    for key in behavior_keys:\n",
    "        if \"on\" in key:\n",
    "            clean_behavior_dict[key] = raw_behavior_df.query(key.split(\"_\")[0] + \" == 1\").index.tolist()\n",
    "        else:\n",
    "            clean_behavior_dict[key] = raw_behavior_df.query(key.split(\"_\")[0] + \" == 1\").index.tolist()\n",
    "\n",
    "    return clean_stimuli_dict, clean_behavior_dict\n",
    "\n",
    "clean_stimuli_dict, clean_behavior_dict = clean_2p_behavior(checked_behavior_file_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5cc36b6-4fbe-4c74-95de-04088f310d50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_2p_trialtypes(twop_config_file):\n",
    "    \"\"\"\n",
    "    Takes in twop configuration file and gives trial types\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1: Path\n",
    "        Path two behavior configuration file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    1. list\n",
    "        Gives list of trial types\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open the json file using json package\n",
    "    with open(twop_config_file, \"r\") as inFile:\n",
    "\n",
    "        # Read the config file\n",
    "        config = inFile.read()\n",
    "\n",
    "        # Decode the file with json.loads()\n",
    "        config_contents = json.loads(config)\n",
    "\n",
    "        # Gather the trial types from the configuration\n",
    "        config_trial_types = config_contents[\"trialArray\"]\n",
    "        \n",
    "    return config_trial_types\n",
    "\n",
    "    \n",
    "config_trial_types = get_2p_trialtypes(twop_config_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1af1d39-8210-42c6-8273-7fa0ffff36f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_base_experiment_df(config_trial_types, clean_stimuli_dict):\n",
    "    \"\"\"\n",
    "    Creates trial DataFrame from configuration trial types\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1: list\n",
    "        List of trial types obtained from get_2p_trialtypes()\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    1. Pandas DataFrame\n",
    "        Returns base dataframe of trial types\n",
    "    \"\"\"\n",
    "    \n",
    "    base_experiment_df = pd.DataFrame()\n",
    "    \n",
    "    liquid_counter = 0\n",
    "    airpuff_counter = 0\n",
    "    \n",
    "    for (index, trial) in enumerate(config_trial_types):\n",
    "        if trial == 1:\n",
    "            liquid_counter += 1\n",
    "            trial_name = \"Trial_\" + str(index + 1)\n",
    "            trial_type = \"Liquid_\" + str(liquid_counter)\n",
    "            series = pd.Series(trial_type, dtype=str, name=trial_name)\n",
    "            base_experiment_df = base_experiment_df.append(series)\n",
    "        else:\n",
    "            airpuff_counter += 1\n",
    "            trial_name = \"Trial_\" + str(index + 1)\n",
    "            trial_type = \"Airpuff_\" + str(airpuff_counter)\n",
    "            series = pd.Series(trial_type, dtype=str, name=trial_name)\n",
    "            base_experiment_df = base_experiment_df.append(series)\n",
    "    \n",
    "    base_experiment_df.reset_index(inplace=True)\n",
    "    base_experiment_df.columns = [\"trial\", \"trial_type\"]\n",
    "    base_experiment_df.set_index(\"trial_type\", inplace=True)\n",
    "    \n",
    "    constant_keys = [key for key in clean_stimuli_dict if len(config_trial_types) == len(clean_stimuli_dict[key])]\n",
    "    \n",
    "    for key in constant_keys:\n",
    "        base_experiment_df[key] = clean_stimuli_dict[key]\n",
    "        base_experiment_df[key] = base_experiment_df[key].divide(1000)\n",
    "    \n",
    "    \n",
    "    variable_keys = [key for key in clean_stimuli_dict if key not in constant_keys and len(clean_stimuli_dict[key]) != 0]\n",
    "    \n",
    "    if len(variable_keys) == 0:\n",
    "        pass\n",
    "    else:\n",
    "\n",
    "        for key in variable_keys:\n",
    "            tmp_df = pd.DataFrame()\n",
    "            if \"Liquid\" in key:\n",
    "                name = \"Liquid_\"\n",
    "            else:\n",
    "                name = \"Airpuff_\"\n",
    "            for (index, trial) in enumerate(clean_stimuli_dict[key]):\n",
    "                tmp_trial = name + str(index + 1)\n",
    "                tmp_timestamp = trial\n",
    "                s = pd.Series(tmp_timestamp, dtype=int, name=tmp_trial)\n",
    "                tmp_df = tmp_df.append(s)\n",
    "            tmp_df.columns = [key]\n",
    "\n",
    "            base_experiment_df[key] = np.nan\n",
    "            base_experiment_df.update(tmp_df)\n",
    "            base_experiment_df[key] = base_experiment_df[key].divide(1000)\n",
    "   \n",
    "    base_experiment_df.reset_index(inplace=True)\n",
    "    base_experiment_df.set_index(\"trial\", inplace=True)\n",
    "    \n",
    "    return base_experiment_df\n",
    "\n",
    "base_df = build_base_experiment_df(config_trial_types, clean_stimuli_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffe3e4c4-bde9-430d-b412-e9fe7de11aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE011\\twop\\20210611\\20210611_LHE011_plane0_merged.h5...done\n"
     ]
    }
   ],
   "source": [
    "def write_merged_behavior_hdf(checked_behavior_file, base_df, config_trialtypes, clean_behavior_dict):\n",
    "    \"\"\"\n",
    "    Writes hdf5 file of cleaned data for a given session to disk\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    1. Path\n",
    "        Path of checked behavior\n",
    "    2. pandas.Dataframe\n",
    "        Cleaned behavior dataframe of trials and stimuli\n",
    "    3. list\n",
    "        List of trial types from configuration file\n",
    "    4. list\n",
    "        List of lick timestamps from cleaned_behavior_dict\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    filename_pattern = re.compile(\"\\d{8}_[A-Z]{3}\\d{3}_plane\\d{1}\")\n",
    "    \n",
    "    re_filename_result = re.search(pattern=filename_pattern, string=checked_behavior_file.name)\n",
    "    \n",
    "    hdf_filename = checked_behavior_file.parents[1] / (re_filename_result.group(0) + \"_merged.h5\")\n",
    "    \n",
    "#     merged_behavior_df.set_index(\"trial\", inplace=True)\n",
    "    \n",
    "    trial_types = pd.Series(config_trialtypes)\n",
    "    \n",
    "    lick_timestamps = pd.DataFrame.from_dict(clean_behavior_dict)\n",
    "    lick_timestamps = lick_timestamps.divide(1000)\n",
    "    \n",
    "    hdf_store = pd.HDFStore(hdf_filename)\n",
    "    \n",
    "    hdf_store.append(value=base_df, key=\"stimulus_timestamps\")\n",
    "    \n",
    "    hdf_store.append(value=trial_types, key=\"trial_types\")\n",
    "    \n",
    "    hdf_store.append(value=lick_timestamps, key=\"lick_timestamps\")\n",
    "    \n",
    "    tables.file._open_files.close_all()\n",
    "    \n",
    "\n",
    "write_merged_behavior_hdf(checked_behavior_file_list[5], base_df, config_trial_types, clean_behavior_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39096bcd-a331-440d-be44-31d05ae1187e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING!!! LHE011 twop 20210602 raw data not converted!\n",
      "Cleaning: 20210603_LHE011_plane0-042_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE011\\twop\\20210603\\20210603_LHE011_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210604_LHE011_plane0-048_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE011\\twop\\20210604\\20210604_LHE011_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210605_LHE011_plane0-056_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE011\\twop\\20210605\\20210605_LHE011_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210607_LHE011_plane0-070_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE011\\twop\\20210607\\20210607_LHE011_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210608_LHE011_plane0-071_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE011\\twop\\20210608\\20210608_LHE011_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210611_LHE011_plane0-081_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE011\\twop\\20210611\\20210611_LHE011_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210612_LHE011_plane0-084_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE011\\twop\\20210612\\20210612_LHE011_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING!!! LHE012 twop 20210602 raw data not converted!\n",
      "Cleaning: 20210603_LHE012_plane0-043_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE012\\twop\\20210603\\20210603_LHE012_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210604_LHE012_plane0-049_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE012\\twop\\20210604\\20210604_LHE012_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210605_LHE012_plane0-057_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE012\\twop\\20210605\\20210605_LHE012_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210606_LHE012_plane0-063_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE012\\twop\\20210606\\20210606_LHE012_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210607_LHE012_plane0-069_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE012\\twop\\20210607\\20210607_LHE012_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210610_LHE012_plane0-078_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE012\\twop\\20210610\\20210610_LHE012_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210611_LHE012_plane0-082_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE012\\twop\\20210611\\20210611_LHE012_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING!!! LHE013 twop 20210602 raw data not converted!\n",
      "Cleaning: 20210603_LHE013_plane0-044_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE013\\twop\\20210603\\20210603_LHE013_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210604_LHE013_plane0-051_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE013\\twop\\20210604\\20210604_LHE013_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210605_LHE013_plane0-058_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE013\\twop\\20210605\\20210605_LHE013_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210606_LHE013_plane0-064_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE013\\twop\\20210606\\20210606_LHE013_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210609_LHE013_plane0-072_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE013\\twop\\20210609\\20210609_LHE013_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210610_LHE013_plane0-076_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE013\\twop\\20210610\\20210610_LHE013_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING!!! LHE014 twop 20210602 raw data not converted!\n",
      "Cleaning: 20210603_LHE014_plane0-045_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE014\\twop\\20210603\\20210603_LHE014_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210604_LHE014_plane0-052_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE014\\twop\\20210604\\20210604_LHE014_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210605_LHE014_plane0-059_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE014\\twop\\20210605\\20210605_LHE014_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210606_LHE014_plane0-065_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE014\\twop\\20210606\\20210606_LHE014_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210609_LHE014_plane0-073_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE014\\twop\\20210609\\20210609_LHE014_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210610_LHE014_plane0-077_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE014\\twop\\20210610\\20210610_LHE014_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING!!! LHE015 twop 20210602 raw data not converted!\n",
      "Cleaning: 20210603_LHE015_plane0-046_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE015\\twop\\20210603\\20210603_LHE015_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210604_LHE015_plane0-053_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE015\\twop\\20210604\\20210604_LHE015_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210605_LHE015_plane0-060_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE015\\twop\\20210605\\20210605_LHE015_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210606_LHE015_plane0-066_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE015\\twop\\20210606\\20210606_LHE015_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210609_LHE015_plane0-074_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE015\\twop\\20210609\\20210609_LHE015_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210610_LHE015_plane0-079_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE015\\twop\\20210610\\20210610_LHE015_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING!!! LHE016 twop 20210602 raw data not converted!\n",
      "Cleaning: 20210603_LHE016_plane0-047_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE016\\twop\\20210603\\20210603_LHE016_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210604_LHE016_plane0-055_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE016\\twop\\20210604\\20210604_LHE016_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210605_LHE016_plane0-061_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE016\\twop\\20210605\\20210605_LHE016_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210606_LHE016_plane0-067_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE016\\twop\\20210606\\20210606_LHE016_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210609_LHE016_plane0-075_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE016\\twop\\20210609\\20210609_LHE016_plane0_merged.h5...done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: 20210610_LHE016_plane0-080_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:Y:\\specialk\\learned_helplessness\\LHE016\\twop\\20210610\\20210610_LHE016_plane0_merged.h5...done\n"
     ]
    }
   ],
   "source": [
    "def merge_bruker_twop_data(data_dir_list):\n",
    "    \n",
    "    for data_dir in data_dir_list:\n",
    "        checked_behavior_file_list = grep_twop_raw_behavior_data(data_dir)\n",
    "        twop_config_list = grep_twop_behavior_config(checked_behavior_file_list)\n",
    "        for file, config in zip(checked_behavior_file_list, twop_config_list):\n",
    "            clean_stimuli_dict, clean_behavior_dict = clean_2p_behavior(file)\n",
    "            config_trial_types = get_2p_trialtypes(config)\n",
    "            base_df = build_base_experiment_df(config_trial_types, clean_stimuli_dict)\n",
    "            write_merged_behavior_hdf(file, base_df, config_trial_types, clean_behavior_dict)\n",
    "        \n",
    "        \n",
    "merge_bruker_twop_data(data_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e0151462-83b9-4509-ac28-38bd9521beb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_type</th>\n",
       "      <th>Speaker_on</th>\n",
       "      <th>Speaker_off</th>\n",
       "      <th>Airpuff_on</th>\n",
       "      <th>Airpuff_off</th>\n",
       "      <th>Liquid_on</th>\n",
       "      <th>Liquid_off</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trial_1</th>\n",
       "      <td>Liquid_1</td>\n",
       "      <td>17.391</td>\n",
       "      <td>20.428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.429</td>\n",
       "      <td>20.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_2</th>\n",
       "      <td>Liquid_2</td>\n",
       "      <td>45.579</td>\n",
       "      <td>47.568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.568</td>\n",
       "      <td>47.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_3</th>\n",
       "      <td>Liquid_3</td>\n",
       "      <td>67.309</td>\n",
       "      <td>69.681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.681</td>\n",
       "      <td>69.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_4</th>\n",
       "      <td>Liquid_4</td>\n",
       "      <td>89.234</td>\n",
       "      <td>90.744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.744</td>\n",
       "      <td>90.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_5</th>\n",
       "      <td>Airpuff_1</td>\n",
       "      <td>118.582</td>\n",
       "      <td>120.241</td>\n",
       "      <td>120.242</td>\n",
       "      <td>120.341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_6</th>\n",
       "      <td>Liquid_5</td>\n",
       "      <td>140.020</td>\n",
       "      <td>145.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.017</td>\n",
       "      <td>145.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_7</th>\n",
       "      <td>Liquid_6</td>\n",
       "      <td>176.417</td>\n",
       "      <td>179.166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179.166</td>\n",
       "      <td>179.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_8</th>\n",
       "      <td>Airpuff_2</td>\n",
       "      <td>211.919</td>\n",
       "      <td>216.455</td>\n",
       "      <td>216.456</td>\n",
       "      <td>216.555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_9</th>\n",
       "      <td>Airpuff_3</td>\n",
       "      <td>242.545</td>\n",
       "      <td>245.172</td>\n",
       "      <td>245.172</td>\n",
       "      <td>245.272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_10</th>\n",
       "      <td>Airpuff_4</td>\n",
       "      <td>272.473</td>\n",
       "      <td>274.689</td>\n",
       "      <td>274.689</td>\n",
       "      <td>274.790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_11</th>\n",
       "      <td>Liquid_7</td>\n",
       "      <td>300.524</td>\n",
       "      <td>302.352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302.352</td>\n",
       "      <td>302.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_12</th>\n",
       "      <td>Liquid_8</td>\n",
       "      <td>332.737</td>\n",
       "      <td>334.413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334.413</td>\n",
       "      <td>334.614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_13</th>\n",
       "      <td>Liquid_9</td>\n",
       "      <td>366.642</td>\n",
       "      <td>369.239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>369.239</td>\n",
       "      <td>369.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_14</th>\n",
       "      <td>Liquid_10</td>\n",
       "      <td>397.856</td>\n",
       "      <td>401.046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>401.046</td>\n",
       "      <td>401.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_15</th>\n",
       "      <td>Airpuff_5</td>\n",
       "      <td>427.251</td>\n",
       "      <td>428.625</td>\n",
       "      <td>428.626</td>\n",
       "      <td>428.726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_16</th>\n",
       "      <td>Liquid_11</td>\n",
       "      <td>452.463</td>\n",
       "      <td>456.066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>456.066</td>\n",
       "      <td>456.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_17</th>\n",
       "      <td>Liquid_12</td>\n",
       "      <td>475.779</td>\n",
       "      <td>477.592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>477.592</td>\n",
       "      <td>477.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_18</th>\n",
       "      <td>Liquid_13</td>\n",
       "      <td>500.187</td>\n",
       "      <td>502.674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>502.675</td>\n",
       "      <td>502.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_19</th>\n",
       "      <td>Liquid_14</td>\n",
       "      <td>530.155</td>\n",
       "      <td>533.975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>533.976</td>\n",
       "      <td>534.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_20</th>\n",
       "      <td>Liquid_15</td>\n",
       "      <td>557.345</td>\n",
       "      <td>561.814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>561.814</td>\n",
       "      <td>562.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_21</th>\n",
       "      <td>Liquid_16</td>\n",
       "      <td>589.984</td>\n",
       "      <td>593.198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>593.199</td>\n",
       "      <td>593.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_22</th>\n",
       "      <td>Liquid_17</td>\n",
       "      <td>619.492</td>\n",
       "      <td>623.558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>623.558</td>\n",
       "      <td>623.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_23</th>\n",
       "      <td>Airpuff_6</td>\n",
       "      <td>654.306</td>\n",
       "      <td>657.853</td>\n",
       "      <td>657.854</td>\n",
       "      <td>657.954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_24</th>\n",
       "      <td>Liquid_18</td>\n",
       "      <td>680.941</td>\n",
       "      <td>683.454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>683.454</td>\n",
       "      <td>683.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_25</th>\n",
       "      <td>Liquid_19</td>\n",
       "      <td>704.235</td>\n",
       "      <td>706.892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>706.892</td>\n",
       "      <td>707.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_26</th>\n",
       "      <td>Liquid_20</td>\n",
       "      <td>734.236</td>\n",
       "      <td>735.805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>735.805</td>\n",
       "      <td>736.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_27</th>\n",
       "      <td>Liquid_21</td>\n",
       "      <td>765.282</td>\n",
       "      <td>769.571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>769.572</td>\n",
       "      <td>769.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_28</th>\n",
       "      <td>Airpuff_7</td>\n",
       "      <td>798.193</td>\n",
       "      <td>800.483</td>\n",
       "      <td>800.484</td>\n",
       "      <td>800.584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_29</th>\n",
       "      <td>Liquid_22</td>\n",
       "      <td>816.775</td>\n",
       "      <td>821.121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>821.121</td>\n",
       "      <td>821.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_30</th>\n",
       "      <td>Airpuff_8</td>\n",
       "      <td>845.217</td>\n",
       "      <td>849.241</td>\n",
       "      <td>849.242</td>\n",
       "      <td>849.341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_31</th>\n",
       "      <td>Liquid_23</td>\n",
       "      <td>870.276</td>\n",
       "      <td>874.636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>874.636</td>\n",
       "      <td>874.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_32</th>\n",
       "      <td>Liquid_24</td>\n",
       "      <td>903.924</td>\n",
       "      <td>907.698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>907.698</td>\n",
       "      <td>907.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_33</th>\n",
       "      <td>Liquid_25</td>\n",
       "      <td>929.162</td>\n",
       "      <td>932.374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>932.374</td>\n",
       "      <td>932.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_34</th>\n",
       "      <td>Liquid_26</td>\n",
       "      <td>958.570</td>\n",
       "      <td>963.416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>963.417</td>\n",
       "      <td>963.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_35</th>\n",
       "      <td>Airpuff_9</td>\n",
       "      <td>983.412</td>\n",
       "      <td>985.643</td>\n",
       "      <td>985.643</td>\n",
       "      <td>985.743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_36</th>\n",
       "      <td>Liquid_27</td>\n",
       "      <td>1009.879</td>\n",
       "      <td>1013.607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013.607</td>\n",
       "      <td>1013.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_37</th>\n",
       "      <td>Liquid_28</td>\n",
       "      <td>1044.646</td>\n",
       "      <td>1049.369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049.370</td>\n",
       "      <td>1049.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_38</th>\n",
       "      <td>Liquid_29</td>\n",
       "      <td>1079.900</td>\n",
       "      <td>1082.844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1082.844</td>\n",
       "      <td>1083.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_39</th>\n",
       "      <td>Airpuff_10</td>\n",
       "      <td>1103.288</td>\n",
       "      <td>1108.140</td>\n",
       "      <td>1108.141</td>\n",
       "      <td>1108.241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trial_40</th>\n",
       "      <td>Liquid_30</td>\n",
       "      <td>1127.202</td>\n",
       "      <td>1129.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1129.004</td>\n",
       "      <td>1129.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          trial_type  Speaker_on  Speaker_off  Airpuff_on  Airpuff_off  \\\n",
       "trial                                                                    \n",
       "Trial_1     Liquid_1      17.391       20.428         NaN          NaN   \n",
       "Trial_2     Liquid_2      45.579       47.568         NaN          NaN   \n",
       "Trial_3     Liquid_3      67.309       69.681         NaN          NaN   \n",
       "Trial_4     Liquid_4      89.234       90.744         NaN          NaN   \n",
       "Trial_5    Airpuff_1     118.582      120.241     120.242      120.341   \n",
       "Trial_6     Liquid_5     140.020      145.016         NaN          NaN   \n",
       "Trial_7     Liquid_6     176.417      179.166         NaN          NaN   \n",
       "Trial_8    Airpuff_2     211.919      216.455     216.456      216.555   \n",
       "Trial_9    Airpuff_3     242.545      245.172     245.172      245.272   \n",
       "Trial_10   Airpuff_4     272.473      274.689     274.689      274.790   \n",
       "Trial_11    Liquid_7     300.524      302.352         NaN          NaN   \n",
       "Trial_12    Liquid_8     332.737      334.413         NaN          NaN   \n",
       "Trial_13    Liquid_9     366.642      369.239         NaN          NaN   \n",
       "Trial_14   Liquid_10     397.856      401.046         NaN          NaN   \n",
       "Trial_15   Airpuff_5     427.251      428.625     428.626      428.726   \n",
       "Trial_16   Liquid_11     452.463      456.066         NaN          NaN   \n",
       "Trial_17   Liquid_12     475.779      477.592         NaN          NaN   \n",
       "Trial_18   Liquid_13     500.187      502.674         NaN          NaN   \n",
       "Trial_19   Liquid_14     530.155      533.975         NaN          NaN   \n",
       "Trial_20   Liquid_15     557.345      561.814         NaN          NaN   \n",
       "Trial_21   Liquid_16     589.984      593.198         NaN          NaN   \n",
       "Trial_22   Liquid_17     619.492      623.558         NaN          NaN   \n",
       "Trial_23   Airpuff_6     654.306      657.853     657.854      657.954   \n",
       "Trial_24   Liquid_18     680.941      683.454         NaN          NaN   \n",
       "Trial_25   Liquid_19     704.235      706.892         NaN          NaN   \n",
       "Trial_26   Liquid_20     734.236      735.805         NaN          NaN   \n",
       "Trial_27   Liquid_21     765.282      769.571         NaN          NaN   \n",
       "Trial_28   Airpuff_7     798.193      800.483     800.484      800.584   \n",
       "Trial_29   Liquid_22     816.775      821.121         NaN          NaN   \n",
       "Trial_30   Airpuff_8     845.217      849.241     849.242      849.341   \n",
       "Trial_31   Liquid_23     870.276      874.636         NaN          NaN   \n",
       "Trial_32   Liquid_24     903.924      907.698         NaN          NaN   \n",
       "Trial_33   Liquid_25     929.162      932.374         NaN          NaN   \n",
       "Trial_34   Liquid_26     958.570      963.416         NaN          NaN   \n",
       "Trial_35   Airpuff_9     983.412      985.643     985.643      985.743   \n",
       "Trial_36   Liquid_27    1009.879     1013.607         NaN          NaN   \n",
       "Trial_37   Liquid_28    1044.646     1049.369         NaN          NaN   \n",
       "Trial_38   Liquid_29    1079.900     1082.844         NaN          NaN   \n",
       "Trial_39  Airpuff_10    1103.288     1108.140    1108.141     1108.241   \n",
       "Trial_40   Liquid_30    1127.202     1129.004         NaN          NaN   \n",
       "\n",
       "          Liquid_on  Liquid_off  \n",
       "trial                            \n",
       "Trial_1      20.429      20.629  \n",
       "Trial_2      47.568      47.768  \n",
       "Trial_3      69.681      69.880  \n",
       "Trial_4      90.744      90.944  \n",
       "Trial_5         NaN         NaN  \n",
       "Trial_6     145.017     145.216  \n",
       "Trial_7     179.166     179.366  \n",
       "Trial_8         NaN         NaN  \n",
       "Trial_9         NaN         NaN  \n",
       "Trial_10        NaN         NaN  \n",
       "Trial_11    302.352     302.553  \n",
       "Trial_12    334.413     334.614  \n",
       "Trial_13    369.239     369.440  \n",
       "Trial_14    401.046     401.247  \n",
       "Trial_15        NaN         NaN  \n",
       "Trial_16    456.066     456.267  \n",
       "Trial_17    477.592     477.792  \n",
       "Trial_18    502.675     502.875  \n",
       "Trial_19    533.976     534.176  \n",
       "Trial_20    561.814     562.014  \n",
       "Trial_21    593.199     593.399  \n",
       "Trial_22    623.558     623.758  \n",
       "Trial_23        NaN         NaN  \n",
       "Trial_24    683.454     683.655  \n",
       "Trial_25    706.892     707.093  \n",
       "Trial_26    735.805     736.005  \n",
       "Trial_27    769.572     769.772  \n",
       "Trial_28        NaN         NaN  \n",
       "Trial_29    821.121     821.321  \n",
       "Trial_30        NaN         NaN  \n",
       "Trial_31    874.636     874.836  \n",
       "Trial_32    907.698     907.898  \n",
       "Trial_33    932.374     932.574  \n",
       "Trial_34    963.417     963.616  \n",
       "Trial_35        NaN         NaN  \n",
       "Trial_36   1013.607    1013.806  \n",
       "Trial_37   1049.370    1049.570  \n",
       "Trial_38   1082.844    1083.044  \n",
       "Trial_39        NaN         NaN  \n",
       "Trial_40   1129.004    1129.204  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf(\"Y:/specialk/learned_helplessness/LHE011/twop/20210608/20210608_LHE011_plane0_merged.h5\", key=\"stimulus_timestamps\")\n",
    "\n",
    "# tables.file._open_files.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "97004ec2-30cf-41a2-a3c4-fca46a58b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_behavior(merged_file, prewindow, postwindow):\n",
    "\n",
    "    session_df = pd.read_hdf(merged_file, key=\"stimulus_timestamps\", index_col=\"trial\")\n",
    "    \n",
    "    \n",
    "    airpuff_trials = [int(item[0].split(\"_\")[1]) - 1 for item in session_df.trial_type.items() if \"Airpuff\" in item[1]]\n",
    "    sucrose_trials = [int(item[0].split(\"_\")[1]) - 1 for item in session_df.trial_type.items() if \"Liquid\" in item[1]]\n",
    "    \n",
    "    lick_dataframe = pd.read_hdf(merged_file, key=\"lick_timestamps\")\n",
    "    \n",
    "    session_df[\"centered_licks\"] = np.empty((len(session_df), 0)).tolist()\n",
    "    session_df[\"aligned_licks\"] = np.empty((len(session_df), 0)).tolist()\n",
    "    \n",
    "    for lick in lick_dataframe[\"Lick_on\"]:\n",
    "        for value in session_df[\"Liquid_on\"].items():\n",
    "            if (value[1] - prewindow) <= lick <= (value[1] + postwindow):\n",
    "                tmp = value[0]\n",
    "                session_df[\"centered_licks\"].loc[tmp].append(lick)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    for lick in session_df[\"centered_licks\"].items():\n",
    "        if len(lick[1]) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            tmp = lick[0]\n",
    "            for value in session_df[\"centered_licks\"].loc[tmp]:\n",
    "                session_df[\"aligned_licks\"].loc[tmp].append((value - session_df[\"Liquid_on\"].loc[tmp]).round(3))\n",
    "\n",
    "    session_liquid_aligned_lists = [lick for lick in session_df[\"aligned_licks\"]]\n",
    "    \n",
    "    return session_liquid_aligned_lists, airpuff_trials, sucrose_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0e5e9690-3517-4b65-9483-f73e3a34ff0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gen_session_lick_raster(merged_file, prewindow=5, postwindow=10):\n",
    "    \n",
    "    session_name = Path(merged_file).stem\n",
    "    \n",
    "    session_liquid_aligned_lists, airpuff_trials, sucrose_trials = align_behavior(merged_file, prewindow, postwindow)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.add_subplot()\n",
    "    plt.xlim(-prewindow, postwindow)\n",
    "    plt.title(Path(merged_file).stem + \" Trial Lick Raster\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Trial Number\")\n",
    "    plt.axvline(x=0, ymin=0, ymax=len(session_liquid_aligned_lists), color=\"green\", label=\"test\")\n",
    "    plt.hlines(y=airpuff_trials, xmin=-prewindow, xmax=postwindow, alpha=0.3, linewidth=9, color=\"red\")\n",
    "    plt.hlines(y=sucrose_trials, xmin=-prewindow, xmax=postwindow, alpha=0.3, linewidth=9, color=\"green\")\n",
    "    ax.eventplot(positions=session_liquid_aligned_lists, linewidth=2.5)\n",
    "\n",
    "gen_session_lick_raster(\"Y:/specialk/learned_helplessness/LHE011/twop/20210608/20210608_LHE011_plane0_merged.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d9f9746c-0d3a-4368-b713-1da9e744e7f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-4d3b94a0fc2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdigitized\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mgen_session_lick_psth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Y:/specialk/learned_helplessness/LHE011/twop/20210608/20210608_LHE011_plane0_merged.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-158-4d3b94a0fc2f>\u001b[0m in \u001b[0;36mgen_session_lick_psth\u001b[1;34m(merged_file, prewindow, postwindow)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdigitized\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mgen_session_lick_psth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Y:/specialk/learned_helplessness/LHE011/twop/20210608/20210608_LHE011_plane0_merged.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-158-4d3b94a0fc2f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdigitized\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mgen_session_lick_psth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Y:/specialk/learned_helplessness/LHE011/twop/20210608/20210608_LHE011_plane0_merged.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "def gen_session_lick_psth(merged_file, prewindow=5, postwindow=10):\n",
    "    \n",
    "    session_name = Path(merged_file).stem\n",
    "    \n",
    "    session_liquid_aligned_lists, airpuff_trials, sucrose_trials = align_behavior(merged_file, prewindow, postwindow)\n",
    "    \n",
    "    psth_licks = []\n",
    "\n",
    "    for entry in session_liquid_aligned_lists:\n",
    "        for lick in entry:\n",
    "            psth_licks.append(lick)\n",
    "    \n",
    "    bins = np.arange(-prewindow, postwindow + 0.5, 0.5)\n",
    "    \n",
    "    digitized = np.digitize(psth_licks, bins, right=True)\n",
    "    \n",
    "    test = []\n",
    "    \n",
    "    means = [test[digitized == i].mean() for i in range(1, len(bins))]\n",
    "        \n",
    "gen_session_lick_psth(\"Y:/specialk/learned_helplessness/LHE011/twop/20210608/20210608_LHE011_plane0_merged.h5\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a492228b-0b4c-4292-83a9-98b1b43b5845",
   "metadata": {},
   "source": [
    "# BELOW THIS POINT IS DEPRECATED/ONLY FOR PICKING APART SCRAPS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "941d2ced-b83b-4260-b590-ae006f924acb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 AIRPUFF LENGTH HERE --------------\n",
      "Empty DataFrame\n",
      "Columns: [Liquid_on, Liquid_off, Speaker_on, Speaker_off]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def build_clean_stimulus_df(clean_behavior_dict):\n",
    "    \"\"\"\n",
    "    Creates cleaned stimulus dataframe of timestamps from cleaned behavior dictionary\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    1. dict\n",
    "        Cleaned behavior dictionary from clean_2p_behavior()\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    1. Pandas DataFrame\n",
    "        Dataframe of cleaned behavior timestamps per trial\n",
    "    \"\"\"\n",
    "    \n",
    "    print(len(clean_behavior_dict[\"Airpuff_on\"]), \"AIRPUFF LENGTH HERE --------------\")\n",
    "    \n",
    "    \n",
    "    if len(clean_behavior_dict[\"Airpuff_on\"]) == 0:\n",
    "        clean_stimulus_df_keys = [key for key in clean_behavior_dict if \"Lick\" not in key and \"Airpuff\" not in key]\n",
    "        \n",
    "    else:\n",
    "        clean_stimulus_df_keys = [key for key in clean_behavior_dict if \"Lick\" not in key]\n",
    "\n",
    "    clean_stimulus_df = pd.DataFrame(columns=clean_stimulus_df_keys)\n",
    "    \n",
    "#     for key in clean_stimulus_df_keys:\n",
    "#         clean_stimulus_df[key] = pd.Series(clean_behavior_dict[key]).divide(1000)\n",
    "    \n",
    "    return clean_stimulus_df\n",
    "\n",
    "clean_df = build_clean_stimulus_df(clean_behavior_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "be21d865-75f8-42b9-a8db-9ef32edb378e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       trial  trial_type Liquid_on Liquid_off Speaker_on Speaker_off\n",
      "0    Trial_1   Sucrose_1       NaN        NaN        NaN         NaN\n",
      "1    Trial_2   Sucrose_2       NaN        NaN        NaN         NaN\n",
      "2    Trial_3   Sucrose_3       NaN        NaN        NaN         NaN\n",
      "3    Trial_4   Sucrose_4       NaN        NaN        NaN         NaN\n",
      "4    Trial_5   Sucrose_5       NaN        NaN        NaN         NaN\n",
      "5    Trial_6   Sucrose_6       NaN        NaN        NaN         NaN\n",
      "6    Trial_7   Sucrose_7       NaN        NaN        NaN         NaN\n",
      "7    Trial_8   Sucrose_8       NaN        NaN        NaN         NaN\n",
      "8    Trial_9   Sucrose_9       NaN        NaN        NaN         NaN\n",
      "9   Trial_10  Sucrose_10       NaN        NaN        NaN         NaN\n",
      "10  Trial_11  Sucrose_11       NaN        NaN        NaN         NaN\n",
      "11  Trial_12  Sucrose_12       NaN        NaN        NaN         NaN\n",
      "12  Trial_13  Sucrose_13       NaN        NaN        NaN         NaN\n",
      "13  Trial_14  Sucrose_14       NaN        NaN        NaN         NaN\n",
      "14  Trial_15  Sucrose_15       NaN        NaN        NaN         NaN\n",
      "15  Trial_16  Sucrose_16       NaN        NaN        NaN         NaN\n",
      "16  Trial_17  Sucrose_17       NaN        NaN        NaN         NaN\n",
      "17  Trial_18  Sucrose_18       NaN        NaN        NaN         NaN\n",
      "18  Trial_19  Sucrose_19       NaN        NaN        NaN         NaN\n",
      "19  Trial_20  Sucrose_20       NaN        NaN        NaN         NaN\n",
      "20  Trial_21  Sucrose_21       NaN        NaN        NaN         NaN\n",
      "21  Trial_22  Sucrose_22       NaN        NaN        NaN         NaN\n",
      "22  Trial_23  Sucrose_23       NaN        NaN        NaN         NaN\n",
      "23  Trial_24  Sucrose_24       NaN        NaN        NaN         NaN\n",
      "24  Trial_25  Sucrose_25       NaN        NaN        NaN         NaN\n",
      "25  Trial_26  Sucrose_26       NaN        NaN        NaN         NaN\n",
      "26  Trial_27  Sucrose_27       NaN        NaN        NaN         NaN\n",
      "27  Trial_28  Sucrose_28       NaN        NaN        NaN         NaN\n",
      "28  Trial_29  Sucrose_29       NaN        NaN        NaN         NaN\n",
      "29  Trial_30  Sucrose_30       NaN        NaN        NaN         NaN\n",
      "30  Trial_31  Sucrose_31       NaN        NaN        NaN         NaN\n",
      "31  Trial_32  Sucrose_32       NaN        NaN        NaN         NaN\n",
      "32  Trial_33  Sucrose_33       NaN        NaN        NaN         NaN\n",
      "33  Trial_34  Sucrose_34       NaN        NaN        NaN         NaN\n",
      "34  Trial_35  Sucrose_35       NaN        NaN        NaN         NaN\n",
      "35  Trial_36  Sucrose_36       NaN        NaN        NaN         NaN\n",
      "36  Trial_37  Sucrose_37       NaN        NaN        NaN         NaN\n",
      "37  Trial_38  Sucrose_38       NaN        NaN        NaN         NaN\n",
      "38  Trial_39  Sucrose_39       NaN        NaN        NaN         NaN\n",
      "39  Trial_40  Sucrose_40       NaN        NaN        NaN         NaN\n"
     ]
    }
   ],
   "source": [
    "def build_behavior_stimulus_df(base_df, clean_df):\n",
    "    \"\"\"\n",
    "    Joins cleaned_stimulus_df and base_behavior_df into one DataFrame\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    1. Pandas DataFrame\n",
    "        Base behavior dataframe (trial types)\n",
    "    2. Pandas DataFrame\n",
    "        Cleaned stimulus dataframe (timestamps)\n",
    "    \n",
    "    Results\n",
    "    -------\n",
    "    1. Pandas DataFrame\n",
    "        Dataframe from united base and stimulus inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    merged_behavior_df = base_df.join(clean_df, how=\"outer\")\n",
    "    \n",
    "#     print(merged_behavior_df)\n",
    "    \n",
    "    return merged_behavior_df\n",
    "    \n",
    "merged_behavior_df = build_behavior_stimulus_df(base_df, clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "44b8c815-42bb-4ef4-9b90-75c69c8613c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Needs Merging: LHE011 20210603\n",
      "Session Needs Merging: LHE011 20210604\n",
      "Session Needs Merging: LHE011 20210605\n",
      "Session Needs Merging: LHE011 20210607\n",
      "Session Needs Merging: LHE011 20210608\n",
      "Session Needs Merging: LHE011 20210611\n",
      "Session Needs Merging: LHE011 20210612\n",
      "Merging: 20210603_LHE011_plane0-042_Cycle00001_VoltageRecording_001.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-698-34ce0ef6818a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmerged_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m \u001b[0mmerged_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge_2p_behavior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwop_raw_beh_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtwop_config_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-698-34ce0ef6818a>\u001b[0m in \u001b[0;36mmerge_2p_behavior\u001b[1;34m(cleaned_behavior_dict, config_trial_types)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;31m# Append trial types to merged file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"trialTypes\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;31m# Create the new file using json package\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: This needs to be done by writing things to HDF5/Zarr in NWB format so a complete dataset for a given session is available for analysis\n",
    "def merge_2p_behavior(clean_behavior_dict, config_trial_types):\n",
    "    \"\"\"\n",
    "    Merges one twop behavior, configuration, video, and microscopy files' data together.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1: dict\n",
    "        Dictionary of cleaned behavior data timestamps\n",
    "    arg2: list\n",
    "        List of trialtypes from configuration file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    1. list\n",
    "        List of merged 2P behavior paths\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Use Kyle's code to align these files with the relative timestamps of microscopy\n",
    "    # TODO: Get zipping of these two lists to work so finding config file is already completed...\n",
    "    # TODO: Make force overwrite/recompile the different datasets\n",
    "    # TODO: Make verbose version of this function\n",
    "    needs_merging = []\n",
    "    \n",
    "    merged_list = []\n",
    "    \n",
    "    # Give name_date pattern for the files we're aligning\n",
    "    name_date_pattern = re.compile(\"\\d{8}_[A-Z]{3}\\d{3}\")\n",
    "    \n",
    "    # First, check for cleaned data\n",
    "    for directory in twop_raw_beh_list:\n",
    "        \n",
    "        # Glob for the aligned json file\n",
    "        cleaned_check = directory.parents[1].glob(\"*_merged.json\")\n",
    "        \n",
    "        # Make a list using the result of the glob using list comprehension\n",
    "        clean_checklist = [session for session in cleaned_check]\n",
    "        \n",
    "        # If the list is empty, the session needs merging\n",
    "        if len(clean_checklist) == 0:\n",
    "            \n",
    "            # Show which session needs alignment and append the directory to needs_merging list\n",
    "            print(\"Session Needs Merging:\", directory.parents[3].name, directory.parents[1].name)\n",
    "            needs_merging.append(directory)\n",
    "        \n",
    "        # Else, the session has already been merged.  Append the filepath to the merged_list.\n",
    "        else:\n",
    "            merged_file = clean_checklist[0]\n",
    "            print(\"Session already merged:\", merged_file)\n",
    "            merged_list.append(merged_file)\n",
    "    \n",
    "    # Now, do the merging\n",
    "    for raw_file in needs_merging:\n",
    "        print(\"Merging:\", raw_file.name)\n",
    "        \n",
    "        merged = {}\n",
    "        \n",
    "        parent_folder = raw_file.parents[1]\n",
    "        \n",
    "        # From Kyle Fischer, June 2021 thru line 92\n",
    "        raw_behavior_df = pd.read_csv(raw_file, index_col=\"Time(ms)\").rename(columns=lambda col:col.strip())\n",
    "        \n",
    "        # Any value below 3V is not signal, turn it to zero by filtering\n",
    "        # values so all that remains are values greater than 3. All else\n",
    "        # will be 0.\n",
    "        raw_behavior_df = raw_behavior_df > 3\n",
    "        \n",
    "        # Convert all values to int; is necessary for pd.df.diff() to produce\n",
    "        # negative values used for stop times of each event\n",
    "        raw_behavior_df = raw_behavior_df.astype(int)\n",
    "        \n",
    "        # Take the diff of each column; gives start and stop of each signal\n",
    "        raw_behavior_df = raw_behavior_df.diff()\n",
    "\n",
    "        # Replace any NaN values with 0\n",
    "        raw_behavior_df = raw_behavior_df.fillna(0)\n",
    "        \n",
    "        # Grab start and stop values for licks\n",
    "        merged[\"LickOn\"] = raw_behavior_df[raw_behavior_df[\"Lick\"] == 1].index.tolist()\n",
    "        merged[\"LickOff\"] = raw_behavior_df[raw_behavior_df[\"Lick\"] == -1].index.tolist()\n",
    "        \n",
    "        # Grab start and stop values for Airpuff Solenoid\n",
    "        merged[\"AirpuffOn\"] = raw_behavior_df[raw_behavior_df[\"Airpuff\"] == 1].index.tolist()\n",
    "        merged[\"AirpuffOff\"] = raw_behavior_df[raw_behavior_df[\"Airpuff\"] == -1].index.tolist()\n",
    "        \n",
    "        # Grab start and stop values for Liquid Solenoid\n",
    "        merged[\"LiquidOn\"] = raw_behavior_df[raw_behavior_df[\"Liquid\"] == 1].index.tolist()\n",
    "        merged[\"LiquidOff\"] = raw_behavior_df[raw_behavior_df[\"Liquid\"] == -1].index.tolist()\n",
    "        \n",
    "        # Grab start and stop values for Speaker\n",
    "        merged[\"SpeakerOn\"] = raw_behavior_df[raw_behavior_df[\"Speaker\"] == 1].index.tolist()\n",
    "        merged[\"SpeakerOff\"] = raw_behavior_df[raw_behavior_df[\"Speaker\"] == -1].index.tolist()\n",
    "        \n",
    "        \n",
    "        #TODO: This should be just one regex, not sure why complete isn't working...\n",
    "        \n",
    "        # Perform the regex for the name and date of the file\n",
    "        r_name_date = re.search(pattern=name_date_pattern, string=raw_file.name)\n",
    "        \n",
    "        # Give the pattern for the plane of interest\n",
    "        plane_pattern = \"_plane\\d{1}\"\n",
    "        \n",
    "        # Perform the regex for the plane number of the file\n",
    "        r_plane = re.search(pattern=plane_pattern, string=raw_file.name)\n",
    "        \n",
    "        # Concatenate strings into final merged file as json type\n",
    "        merged_name = r_name_date.group(0) + r_plane.group(0) + \"_merged.json\"\n",
    "        \n",
    "        # Append the parent folder with this name to create the file later\n",
    "        merged_filename = parent_folder / merged_name\n",
    "        \n",
    "        # Grab the config file for this plane from the parent folder\n",
    "        config_glob = parent_folder.glob(\"*.json\")\n",
    "        \n",
    "        # Config gather the config file result in a list\n",
    "        config_file_result = [config for config in config_glob]\n",
    "        \n",
    "        # The config file is the only element of this list, not sure how to retain only the relevant file without lists...\n",
    "        config_file = config_file_result[0]\n",
    "        \n",
    "        # Open the json file using json package\n",
    "        with open(config_file, \"r\") as inFile:\n",
    "            \n",
    "            # The configuration is the read file\n",
    "            config = inFile.read()\n",
    "            \n",
    "            # Load the contents of the config with json.loads()\n",
    "            config_contents = json.loads(config)\n",
    "            \n",
    "            # Gather the trial types from the configuration\n",
    "            trial_types = config_contents[\"trialArray\"]\n",
    "        \n",
    "        # Append trial types to merged file\n",
    "        merged_df[\"trialTypes\"] = trial_types\n",
    "\n",
    "        # Create the new file using json package\n",
    "        with open(merged_filename, \"w\") as outFile:\n",
    "            \n",
    "            # Use json.dump to write aligned_dictionary to file\n",
    "            json.dump(merged, outFile)\n",
    "        \n",
    "        # Tell user the file has been written\n",
    "        print(\"Written\", merged_filename)\n",
    "        aligned_list.append(merged_filename)\n",
    "        \n",
    "    return merged_list\n",
    "\n",
    "merged_list = merge_2p_behavior(twop_raw_beh_list, twop_config_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "5722d9a1-ffdc-4492-a88a-b68ac60228f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Needs Alignment: LHE011 20210603\n",
      "Session Needs Alignment: LHE011 20210604\n",
      "Session Needs Alignment: LHE011 20210605\n",
      "Session Needs Alignment: LHE011 20210607\n",
      "Session Needs Alignment: LHE011 20210608\n",
      "Session Needs Alignment: LHE011 20210611\n",
      "Session Needs Alignment: LHE011 20210612\n",
      "Session Needs Alignment: LHE012 20210603\n",
      "Session Needs Alignment: LHE012 20210604\n",
      "Session Needs Alignment: LHE012 20210605\n",
      "Session Needs Alignment: LHE012 20210606\n",
      "Session Needs Alignment: LHE012 20210607\n",
      "Session Needs Alignment: LHE012 20210610\n",
      "Session Needs Alignment: LHE012 20210611\n",
      "Session Needs Alignment: LHE013 20210603\n",
      "Session Needs Alignment: LHE013 20210604\n",
      "Session Needs Alignment: LHE013 20210605\n",
      "Session Needs Alignment: LHE013 20210606\n",
      "Session Needs Alignment: LHE013 20210610\n",
      "Session Needs Alignment: LHE014 20210603\n",
      "Session Needs Alignment: LHE014 20210604\n",
      "Session Needs Alignment: LHE014 20210605\n",
      "Session Needs Alignment: LHE014 20210606\n",
      "Session Needs Alignment: LHE014 20210609\n",
      "Session Needs Alignment: LHE014 20210610\n",
      "Session Needs Alignment: LHE015 20210603\n",
      "Session Needs Alignment: LHE015 20210604\n",
      "Session Needs Alignment: LHE015 20210605\n",
      "Session Needs Alignment: LHE015 20210606\n",
      "Session Needs Alignment: LHE015 20210609\n",
      "Session Needs Alignment: LHE015 20210610\n",
      "Session Needs Alignment: LHE015 20210611\n",
      "Session Needs Alignment: LHE016 20210603\n",
      "Session Needs Alignment: LHE016 20210604\n",
      "Session Needs Alignment: LHE016 20210605\n",
      "Session Needs Alignment: LHE016 20210606\n",
      "Session Needs Alignment: LHE016 20210609\n",
      "Session Needs Alignment: LHE016 20210610\n"
     ]
    }
   ],
   "source": [
    "# TODO: This alignment function should be used to align lick rasters specifically, these alignment positions should not be written out to disk\n",
    "# However, I will be keeping it as a means of hosting static datasets for use on a sideproject that will display static datasets online for the lab...\n",
    "\n",
    "\n",
    "# TODO: Write the merged datafile using some of this code, eventually should be incorporated into raster plot generation/psth/lick probability functions\n",
    "# TODO: Get this to incorporate the training data from the headfix boxes\n",
    "# TODO: Should not rely upon aligned file\n",
    "def align_2p_behavior(merged_list, alignment_positions=[\"LiquidOn\", \"SpeakerOn\", \"AirpuffOn\"], prewindow=5, postwindow=5):\n",
    "    \"\"\"\n",
    "    Aligns twop behavior to different positions from user within specific windows\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1: list\n",
    "        List of paths for merged behavior data\n",
    "    arg2: list\n",
    "        Alignment positions to store\n",
    "    arg3: int\n",
    "        Window (in seconds) for pre/post event alignment\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    1. list\n",
    "        List of aligned 2P behavior paths\n",
    "    \"\"\"\n",
    "\n",
    "    needs_alignment = []\n",
    "    \n",
    "    aligned_list = []\n",
    "    \n",
    "    # First, check for cleaned data\n",
    "    for directory in merged_list:\n",
    "        \n",
    "        clean_name_pattern = \"*aligned_window\" + str(window) + \"*\"\n",
    "        \n",
    "        # Glob for the aligned json file\n",
    "        cleaned_check = directory.parents[0].glob(clean_name_pattern)\n",
    "        \n",
    "        # Make a list using the result of the glob using list comprehension\n",
    "        clean_checklist = [session for session in cleaned_check]\n",
    "        \n",
    "        # If the list is empty, the session needs alignment\n",
    "        if len(clean_checklist) == 0:\n",
    "            \n",
    "            # Show which session needs alignment and append the directory to needs_merging list\n",
    "            print(\"Session Needs Alignment:\", directory.parents[2].name, directory.parents[0].name)\n",
    "            needs_alignment.append(directory)\n",
    "        \n",
    "        # Else, the session has already been aligned.  Append the filepath to the aligned_list.\n",
    "        else:\n",
    "            aligned_file = clean_checklist[0]\n",
    "            print(\"Session already aligned:\", aligned_file)\n",
    "            aligned_list.append(aligned_file)\n",
    "\n",
    "    for merged_file in needs_alignment:\n",
    "\n",
    "        with open(merged_file, \"r\") as inFile:\n",
    "\n",
    "            contents = inFile.read()\n",
    "\n",
    "            timestamps = json.loads(contents)\n",
    "\n",
    "        trial_df = pd.DataFrame()\n",
    "        \n",
    "        lick_timestamps = []\n",
    "        liquid_counter = 0\n",
    "        airpuff_counter = 0\n",
    "\n",
    "        # TODO: Each segment should be its own function call ie liquidon, speakers, airpuffon\n",
    "        for (index, trial) in enumerate(timestamps[\"trialTypes\"]):\n",
    "            if trial == 1:\n",
    "                liquid_counter += 1\n",
    "                trial_name = \"Trial_\" + str(index + 1)\n",
    "                trial_type = \"Sucrose_\" + str(liquid_counter)\n",
    "                s = pd.Series(trial_type, dtype=str, name=trial_name)\n",
    "                trial_df = trial_df.append(s)\n",
    "            else:\n",
    "                airpuff_counter += 1\n",
    "                trial_name = \"Trial_\" + str(index + 1)\n",
    "                trial_type = \"Airpuff_\" + str(airpuff_counter)\n",
    "                s = pd.Series(trial_type, dtype=str, name=trial_name)\n",
    "                trial_df = trial_df.append(s)\n",
    "        \n",
    "        trial_df.index.name = \"trial\"\n",
    "        trial_df.columns = [\"trial_type\"]\n",
    "        \n",
    "        exclude_keys = [\"LickOn\", \"LickOff\", \"LiquidOff\", \"AirpuffOff\", \"trialTypes\"]\n",
    "        \n",
    "        for key in timestamps.keys():\n",
    "            if key not in exclude_keys:\n",
    "                trial_df[key] = np.nan\n",
    "        \n",
    "        speakeron_df = pd.DataFrame()\n",
    "        \n",
    "        for (index, trial) in enumerate(timestamps[\"SpeakerOn\"]):\n",
    "            trial_number = \"Trial_\" + str(index + 1)\n",
    "            speaker_on_ms = trial\n",
    "            s = pd.Series(speaker_on_ms, name=trial_number)\n",
    "            speakeron_df = speakeron_df.append(s)\n",
    "        \n",
    "        speakeron_df.index.name = \"trial\"\n",
    "        speakeron_df.columns = [\"SpeakerOn\"]\n",
    "        \n",
    "        trial_df.update(speakeron_df)\n",
    "        \n",
    "        trial_df[\"SpeakerOn\"] = trial_df[\"SpeakerOn\"].divide(1000)\n",
    "        \n",
    "        speakeroff_df = pd.DataFrame()\n",
    "        \n",
    "        for (index, trial) in enumerate(timestamps[\"SpeakerOff\"]):\n",
    "            \n",
    "            trial_number = \"Trial_\" + str(index + 1)\n",
    "            speaker_off_ms = trial\n",
    "            s = pd.Series(speaker_off_ms, dtype=int, name=trial_number)\n",
    "            speakeroff_df = speakeroff_df.append(s)\n",
    "        \n",
    "        speakeroff_df.index.name = \"trial\"\n",
    "        speakeroff_df.columns = [\"SpeakerOff\"]\n",
    "        \n",
    "        trial_df.update(speakeroff_df)\n",
    "        \n",
    "        trial_df[\"SpeakerOff\"] = trial_df[\"SpeakerOff\"].divide(1000)\n",
    "        \n",
    "        trial_df.reset_index(inplace=True)\n",
    "        trial_df.set_index(\"trial_type\", inplace=True)\n",
    "\n",
    "        \n",
    "        liquid_df = pd.DataFrame()\n",
    "\n",
    "        for (index, trial) in enumerate(timestamps[\"LiquidOn\"]):\n",
    "            \n",
    "            liquid_trial = \"Sucrose_\" + str(index + 1)\n",
    "            liquid_start_ms = trial\n",
    "            s = pd.Series(liquid_start_ms, dtype=int, name=liquid_trial)\n",
    "            liquid_df = liquid_df.append(s)\n",
    "        \n",
    "        liquid_df.index.name = \"trial_type\"\n",
    "        liquid_df.columns = [\"LiquidOn\"]\n",
    "        \n",
    "        trial_df.update(liquid_df)\n",
    "        \n",
    "        trial_df[\"LiquidOn\"] = trial_df[\"LiquidOn\"].divide(1000)\n",
    "        \n",
    "        airpuff_df = pd.DataFrame()\n",
    "\n",
    "        for (index, trial) in enumerate(timestamps[\"AirpuffOn\"]):\n",
    "            airpuff_trial = \"Airpuff_\" + str(index + 1)\n",
    "            airpuff_start_ms = trial\n",
    "            s = pd.Series(airpuff_start_ms, dtype=int, name=airpuff_trial)\n",
    "            airpuff_df = airpuff_df.append(s)\n",
    "        \n",
    "        airpuff_df.index.name = \"trial_type\"\n",
    "        \n",
    "        if airpuff_df.size > 0:\n",
    "            airpuff_df.columns = [\"AirpuffOn\"]\n",
    "            trial_df.update(airpuff_df)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        trial_df.reset_index(inplace=True)\n",
    "        trial_df.set_index(\"trial\", inplace=True)\n",
    "        \n",
    "        trial_df[\"AirpuffOn\"] = trial_df[\"AirpuffOn\"].divide(1000)\n",
    "        \n",
    "        # Use list comprehension for lick timestamps\n",
    "        lick_timestamps = [lick for (index, lick) in enumerate(timestamps[\"LickOn\"])]\n",
    "        \n",
    "        lick_timestamps = [lick/1000 for lick in lick_timestamps]\n",
    "        \n",
    "        # Create columns for aligning licks to different events and then create lick lists\n",
    "        # This is terrible and a better way to assign licks to a list should be found, but\n",
    "        # without using a relational system I'm not sure how I can alter this...\n",
    "        # TODO: Make this a function that is iterated over instead of multiple for loops like this...\n",
    "        # Possible solutions: Create ITI starts/stops as dataframe values and evaluate against range\n",
    "        \n",
    "        for target in alignment_positions:\n",
    "            column = target + \"_licks\"\n",
    "            trial_df[column] = np.empty((len(trial_df), 0)).tolist()\n",
    "            for lick_time in lick_timestamps:\n",
    "                for value in trial_df[target].items():\n",
    "                    if (value[1] - prewindow) <= lick_time <= (value[1] + postwindow):\n",
    "                        tmp = value[0]\n",
    "                        trial_df[column].loc[tmp].append(lick_time)\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "        # Create empty lists for ITI licks\n",
    "        trial_df[\"ITI_licks\"] = np.empty((len(trial_df), 0)).tolist()\n",
    "\n",
    "        # Get leftover ITI licks by creating sets out of aligned licks\n",
    "        accounted_licks = []\n",
    "        for value in trial_df[\"LiquidOn_licks\"].items():\n",
    "            if len(value[1]) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                for licks in value[1]:\n",
    "                    accounted_licks.append(licks)\n",
    "        \n",
    "        accounted_licks = set(accounted_licks)\n",
    "        licks_set = set(lick_timestamps) \n",
    "        iti_licks = list(licks_set - accounted_licks)\n",
    "\n",
    "\n",
    "        # Again, a bad way to do this. Too many loops and likely to be quite slow...\n",
    "        for lick_time in iti_licks:\n",
    "            for value in trial_df[\"ITI_licks\"].items():\n",
    "                tmp = value[0]\n",
    "                if (trial_df[\"SpeakerOn\"].loc[tmp] - prewindow) <= lick_time <= (trial_df[\"LiquidOn\"].loc[tmp] + postwindow):\n",
    "                    trial_df[\"ITI_licks\"].loc[tmp].append(lick_time)\n",
    "\n",
    "        aligned_filename = merged_file.stem\n",
    "        aligned_filename = aligned_filename.replace(\"merged\", \"aligned\")\n",
    "        aligned_filename = aligned_filename + \"_\" + \"window\" + str(window) + \".csv\"\n",
    "        \n",
    "        aligned_file_path = merged_file.parents[0] / aligned_filename\n",
    "        \n",
    "        aligned_list.append(aligned_file_path)\n",
    "        \n",
    "        trial_df.to_csv(aligned_file_path)\n",
    "\n",
    "    return aligned_list\n",
    "\n",
    "\n",
    "aligned_list = align_2p_behavior(merged_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d7e62f-d559-46a9-a377-abe5a9a426ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
